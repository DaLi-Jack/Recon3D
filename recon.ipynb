{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# fix seed\n",
    "import numpy as np\n",
    "import random\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = 'sss_bg_chair'\n",
    "prompt_name = None\n",
    "img_path = f'test_img/origin_img/{img_name}.png'\n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"segment-anything/\")        # add segment-anything to PYTHONPATH\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    "sam_checkpoint = \"segment-anything/checkpoints/sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "predictor.set_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis object mask\n",
    "# the dog\n",
    "input_point = np.array([[350, 300], [500, 400], [200, 100]])            # [W, H], more points for total mask\n",
    "input_label = np.array([1, 1, 1])\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n",
    "show_points(input_point, input_label, plt.gca())\n",
    "plt.axis('on')\n",
    "plt.show()\n",
    "\n",
    "obj_vis_masks, scores, logits = predictor.predict(\n",
    "    point_coords=input_point,\n",
    "    point_labels=input_label,\n",
    "    multimask_output=False,\n",
    ")\n",
    "\n",
    "obj_vis_masks.shape  # (number_of_masks) x H x W\n",
    "# show mask\n",
    "for i, (mask, score) in enumerate(zip(obj_vis_masks, scores)):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image)\n",
    "    show_mask(mask, plt.gca())\n",
    "    show_points(input_point, input_label, plt.gca())\n",
    "    plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "obj_vis_masks = obj_vis_masks.transpose(1, 2, 0)  # H x W x 1\n",
    "obj_vis_masks.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate crop bbox\n",
    "height, width, _ = obj_vis_masks.shape\n",
    "vis_masks_idx = np.argwhere(obj_vis_masks == 1)\n",
    "vis_masks_idx.shape\n",
    "px = vis_masks_idx[:, 0]\n",
    "py = vis_masks_idx[:, 1]\n",
    "xmin, xmax = int(np.min(py)), int(np.max(py))       # W\n",
    "ymin, ymax = int(np.min(px)), int(np.max(px))       # H\n",
    "full_bbox_2d = [xmin, ymin, xmax, ymax]\n",
    "x_center, y_center = (xmin + xmax) // 2, (ymin + ymax) // 2\n",
    "\n",
    "square_length = max(xmax - xmin, ymax - ymin) + 100\n",
    "x_square_begin, y_square_begin = max(0, x_center - square_length // 2), max(0, y_center - square_length // 2)\n",
    "[x_square_end, y_square_end] = [min(width, x_square_begin + square_length), min(height, y_square_begin + square_length)]\n",
    "crop_bbox = [x_square_begin, y_square_begin, x_square_end, y_square_end]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n",
    "show_box(crop_bbox, plt.gca())\n",
    "plt.show()\n",
    "\n",
    "# get vis object image, use PIL\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open(img_path)\n",
    "img_np = np.array(img)\n",
    "height, width, _ = img_np.shape\n",
    "\n",
    "save_vis_img = np.ones((height, width, 3), dtype=np.uint8) * 225\n",
    "save_vis_img[obj_vis_masks[:, :, 0] == 1] = img_np[obj_vis_masks[:, :, 0] == 1]\n",
    "save_vis_img = save_vis_img[y_square_begin:y_square_end, x_square_begin:x_square_end, :]            # crop square image\n",
    "save_vis_img = Image.fromarray(save_vis_img)\n",
    "# save_vis_img.show()\n",
    "save_vis_img.save(f'test_img/seg_img/{img_name}_vis.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffuser mask\n",
    "# the cat\n",
    "input_point = np.array([[350, 350]])            # [W, H]\n",
    "input_label = np.array([1])\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n",
    "show_points(input_point, input_label, plt.gca())\n",
    "plt.axis('on')\n",
    "plt.show()\n",
    "\n",
    "diffuser_masks, scores, logits = predictor.predict(\n",
    "    point_coords=input_point,\n",
    "    point_labels=input_label,\n",
    "    multimask_output=False,\n",
    ")\n",
    "\n",
    "diffuser_masks.shape  # (number_of_masks) x H x W\n",
    "# # show mask\n",
    "# for i, (mask, score) in enumerate(zip(diffuser_masks, scores)):\n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     plt.imshow(image)\n",
    "#     show_mask(mask, plt.gca())\n",
    "#     show_points(input_point, input_label, plt.gca())\n",
    "#     plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "diffuser_masks = diffuser_masks.transpose(1, 2, 0)  # H x W x 1\n",
    "diffuser_masks.shape\n",
    "\n",
    "# save diffuser mask\n",
    "diffuser_masks = diffuser_masks.astype(np.uint8)\n",
    "crop_diffuse_mask = diffuser_masks[y_square_begin:y_square_end, x_square_begin:x_square_end, :]            # setting crop, must be square            # setting crop, must be square\n",
    "crop_diffuse_mask = crop_diffuse_mask[:, :, 0]\n",
    "save_diffuse_mask = Image.fromarray(crop_diffuse_mask * 255)\n",
    "# save_diffuse_mask.show()\n",
    "save_diffuse_mask.save(f'test_img/seg_img/{img_name}_diffuse_mask.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-inpainting\",\n",
    "    revision=\"fp16\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "def img_resize(img, size):\n",
    "    img = img.resize(size, Image.ANTIALIAS)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a table\"\n",
    "prompt_name = prompt.replace(' ', '_')\n",
    "#image and mask_image should be PIL images.\n",
    "#The mask structure is white for inpainting and black for keeping as is\n",
    "image = Image.open(f'test_img/seg_img/{img_name}_vis.jpg')\n",
    "image = img_resize(image, (512, 512))\n",
    "mask_image = Image.open(f'test_img/seg_img/{img_name}_diffuse_mask.jpg')\n",
    "# mask_image = gray2rgb(np.array(mask_image))\n",
    "mask_image = img_resize(mask_image, (512, 512))\n",
    "image = pipe(prompt=prompt, image=image, mask_image=mask_image).images[0]\n",
    "# image = pipe(image=image, mask_image=mask_image).images[0]\n",
    "image.save(f'test_img/inpainting_img/{img_name}_{prompt_name}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "sys.path.append(\"shap-e/\")          # add shap-e to PYTHONPATH\n",
    "from shap_e.diffusion.sample import sample_latents\n",
    "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
    "from shap_e.models.download import load_model, load_config\n",
    "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget\n",
    "from shap_e.util.image_util import load_image\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "xm = load_model('transmitter', device=device, cache_dir='shap-e/shap_e/examples/shap_e_model_cache')\n",
    "model = load_model('image300M', device=device, cache_dir='shap-e/shap_e/examples/shap_e_model_cache')\n",
    "diffusion = diffusion_from_config(load_config('diffusion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "guidance_scale = 3.0\n",
    "\n",
    "# To get the best result, you should remove the background and show only the object of interest to the model.\n",
    "if prompt_name == None:                     # not use diffuser inpainting\n",
    "    prompt_name = 'vis'\n",
    "image = load_image(f\"test_img/inpainting_img/{img_name}_{prompt_name}.jpg\")\n",
    "os.makedirs(f'test_img/recon3D/{img_name}_{prompt_name}', exist_ok=True)\n",
    "\n",
    "latents = sample_latents(\n",
    "    batch_size=batch_size,\n",
    "    model=model,\n",
    "    diffusion=diffusion,\n",
    "    guidance_scale=guidance_scale,\n",
    "    model_kwargs=dict(images=[image] * batch_size),\n",
    "    progress=True,\n",
    "    clip_denoised=True,\n",
    "    use_fp16=True,\n",
    "    use_karras=True,\n",
    "    karras_steps=64,\n",
    "    sigma_min=1e-3,\n",
    "    sigma_max=160,\n",
    "    s_churn=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of saving the latents as meshes.\n",
    "from shap_e.util.notebooks import decode_latent_mesh\n",
    "save_mesh_path = os.path.join(f'test_img/recon3D/{img_name}_{prompt_name}', 'mesh')\n",
    "os.makedirs(save_mesh_path, exist_ok=True)\n",
    "\n",
    "for i, latent in enumerate(latents):\n",
    "    t = decode_latent_mesh(xm, latent).tri_mesh()\n",
    "    with open(os.path.join(save_mesh_path, f'example_mesh_{i}.ply'), 'wb') as f:\n",
    "        t.write_ply(f)\n",
    "    with open(os.path.join(save_mesh_path, f'example_mesh_{i}.obj'), 'w') as f:\n",
    "        t.write_obj(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_mode = 'nerf' # you can change this to 'stf' for mesh rendering\n",
    "size = 128 # this is the size of the renders; higher values take longer to render.\n",
    "\n",
    "cameras = create_pan_cameras(size, device)\n",
    "for i, latent in enumerate(latents):\n",
    "    images = decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)\n",
    "    # display(gif_widget(images))\n",
    "\n",
    "save_root_path = os.path.join(f'test_img/recon3D/{img_name}_{prompt_name}', 'renders')\n",
    "os.makedirs(save_root_path, exist_ok=True)\n",
    "img_idx = 0\n",
    "for image in images:\n",
    "    image.save(os.path.join(save_root_path, f'{img_idx}.png'))\n",
    "    img_idx += 1\n",
    "print('save over!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('recon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "904961b907cc179843f882fdddb3a450768ecca46d984b294d0ce9138a581b86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
